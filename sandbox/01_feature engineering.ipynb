{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание новых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/retailhero-uplift/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000012768d</td>\n",
       "      <td>2017-08-05 15:40:48</td>\n",
       "      <td>2018-01-04 19:30:07</td>\n",
       "      <td>45</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000036f903</td>\n",
       "      <td>2017-04-10 13:54:23</td>\n",
       "      <td>2017-04-23 12:37:56</td>\n",
       "      <td>72</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00010925a5</td>\n",
       "      <td>2018-07-24 16:21:29</td>\n",
       "      <td>2018-09-14 16:12:49</td>\n",
       "      <td>83</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001f552b0</td>\n",
       "      <td>2017-06-30 19:20:38</td>\n",
       "      <td>2018-08-28 12:59:45</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00020e7b18</td>\n",
       "      <td>2017-11-27 11:41:45</td>\n",
       "      <td>2018-01-10 17:50:05</td>\n",
       "      <td>73</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id     first_issue_date    first_redeem_date  age gender  \\\n",
       "0  000012768d  2017-08-05 15:40:48  2018-01-04 19:30:07   45      U   \n",
       "1  000036f903  2017-04-10 13:54:23  2017-04-23 12:37:56   72      F   \n",
       "2  00010925a5  2018-07-24 16:21:29  2018-09-14 16:12:49   83      U   \n",
       "3  0001f552b0  2017-06-30 19:20:38  2018-08-28 12:59:45   33      F   \n",
       "4  00020e7b18  2017-11-27 11:41:45  2018-01-10 17:50:05   73      U   \n",
       "\n",
       "   treatment_flg  target  \n",
       "0              0       1  \n",
       "1              1       1  \n",
       "2              1       1  \n",
       "3              1       1  \n",
       "4              1       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplift = pd.read_csv(path + '/train.csv', encoding='utf-8')\n",
    "uplift.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200039 entries, 0 to 200038\n",
      "Data columns (total 7 columns):\n",
      "client_id            200039 non-null object\n",
      "first_issue_date     200039 non-null object\n",
      "first_redeem_date    182493 non-null object\n",
      "age                  200039 non-null int64\n",
      "gender               200039 non-null object\n",
      "treatment_flg        200039 non-null int64\n",
      "target               200039 non-null int64\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "uplift.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_datetime</th>\n",
       "      <th>regular_points_received</th>\n",
       "      <th>express_points_received</th>\n",
       "      <th>regular_points_spent</th>\n",
       "      <th>express_points_spent</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_quantity</th>\n",
       "      <th>trn_sum_from_iss</th>\n",
       "      <th>trn_sum_from_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>9a80204f78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>da89ebd374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>0a95e1151d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>4055b15e4a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000012768d</td>\n",
       "      <td>7e3e2e3984</td>\n",
       "      <td>2018-12-01 07:12:45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>54a4a11a29</td>\n",
       "      <td>a685f1916b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    client_id transaction_id transaction_datetime  regular_points_received  \\\n",
       "0  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "1  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "2  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "3  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "4  000012768d     7e3e2e3984  2018-12-01 07:12:45                     10.0   \n",
       "\n",
       "   express_points_received  regular_points_spent  express_points_spent  \\\n",
       "0                      0.0                   0.0                   0.0   \n",
       "1                      0.0                   0.0                   0.0   \n",
       "2                      0.0                   0.0                   0.0   \n",
       "3                      0.0                   0.0                   0.0   \n",
       "4                      0.0                   0.0                   0.0   \n",
       "\n",
       "   purchase_sum    store_id  product_id  product_quantity  trn_sum_from_iss  \\\n",
       "0        1007.0  54a4a11a29  9a80204f78               2.0              80.0   \n",
       "1        1007.0  54a4a11a29  da89ebd374               1.0              65.0   \n",
       "2        1007.0  54a4a11a29  0a95e1151d               1.0              24.0   \n",
       "3        1007.0  54a4a11a29  4055b15e4a               2.0              50.0   \n",
       "4        1007.0  54a4a11a29  a685f1916b               1.0              22.0   \n",
       "\n",
       "   trn_sum_from_red  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchases = pd.read_csv(path + '/purchases.csv', encoding='utf-8')\n",
    "purchases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45786568 entries, 0 to 45786567\n",
      "Data columns (total 13 columns):\n",
      "client_id                  object\n",
      "transaction_id             object\n",
      "transaction_datetime       object\n",
      "regular_points_received    float64\n",
      "express_points_received    float64\n",
      "regular_points_spent       float64\n",
      "express_points_spent       float64\n",
      "purchase_sum               float64\n",
      "store_id                   object\n",
      "product_id                 object\n",
      "product_quantity           float64\n",
      "trn_sum_from_iss           float64\n",
      "trn_sum_from_red           float64\n",
      "dtypes: float64(8), object(5)\n",
      "memory usage: 4.4+ GB\n"
     ]
    }
   ],
   "source": [
    "purchases.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечение признаков из временных меток:\n",
    " - месяц\n",
    " - день недели\n",
    " - час"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из файла с покупками сделаем такие признаки за всю историю и последние 30 дней: \n",
    "   - общее количество покупок(штуки и суммы)\n",
    "   - количество накопленных баллов\n",
    "   - количество потраченных баллов\n",
    "   - баланс баллов\n",
    "   - количество уникальных магазинов, где были совершены покупки\n",
    "   - количество дней между первой и последней покупкой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим описательные статистики:\n",
    " - среднее\n",
    " - стандартное отклонение\n",
    " - квартили\n",
    " - минимумы\n",
    " - максимумы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И добавим функциональные зависимости:\n",
    " - полиномы\n",
    " - логарифмы\n",
    " - экспоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Используемые классы и функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для выбора колонки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для преобразования возраста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesTransformator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key, age_min: int = 16, age_max: int = 80):\n",
    "        self.key = key\n",
    "        self.age_min = age_min\n",
    "        self.age_max = age_max\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, age_min, age_max):\n",
    "        X.loc[X[self.key] > age_max, key] = age_max\n",
    "        X.loc[X[self.key] < age_min, key] = age_min\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для извлечения признаков из временных меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X[self.key+'_'+'month'] = X[self.key].dt.month\n",
    "        X[self.key+'_'+'weekday'] = X[self.key].dt.weekday\n",
    "        X[self.key+'_'+'hour'] = X[self.column].dt.hour\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для создания признаков: описательные статистики, функциональные зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesGenerator:\n",
    "    \n",
    "    def load_pd(self, pd_dataframe):\n",
    "        self.df = pd_dataframe\n",
    "    \n",
    "    def base_statistics(self, column):\n",
    "        self.df[column+'_'+'max'] = self.df[column].max()\n",
    "        self.df[column+'_'+'min'] = self.df[column].min()\n",
    "        self.df[column+'_'+'mean'] = self.df[column].mean()\n",
    "        self.df[column+'_'+'std'] = self.df[column].std()\n",
    "        self.df[column+'_'+'q1'] = self.df[column].quantile([0.25])\n",
    "        self.df[column+'_'+'q2'] = self.df[column].quantile([0.5])\n",
    "        self.df[column+'_'+'q3'] = self.df[column].quantile([0.75])\n",
    "    \n",
    "    def polynomizer(self, column, n=2):\n",
    "        for i in range(2,n+1):\n",
    "            self.df[column+'_'+str(i)] = self.df[column]**i\n",
    "                \n",
    "    def naturalize(self, columns, tol=1.01):\n",
    "        self.df[column+'_'+'log'] = np.log(self.df[column] + tol) \n",
    "        self.df[column+'_'+'exp'] = np.exp(self.df[column] + tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для создания фичей из purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PurchaseFeatures:\n",
    "    \n",
    "    def load_pd(self, pd_dataframe1, pd_dataframe2):\n",
    "        self.df1 = pd_dataframe1\n",
    "        self.df2 = pd_dataframe2\n",
    "        \n",
    "    def get_sum(self, columns):\n",
    "        for column in columns:\n",
    "            self.df1[column+'_'+'total'] = self.df1.groupby('client_id')[column].sum()\n",
    "            self.df2[column+'_'+'last'] = self.df2.groupby('client_id')[column].sum()\n",
    "            \n",
    "    def get_unique(self, columns):\n",
    "        for column in columns:\n",
    "            self.df1[column+'_'+'total_unique'] = self.df1.groupby('client_id')[[column]].nunique()\n",
    "            self.df2[column+'_'+'last_unique'] = self.df2.groupby('client_id')[[column]].nunique()\n",
    "    \n",
    "    def get_balance(self, columns):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purchase_features(df):\n",
    "    last_cols = ['regular_points_received', 'express_points_received','regular_points_spent', \n",
    "                 'express_points_spent', 'purchase_sum','store_id', 'product_quantity']\n",
    "    all_hist = df.groupby(['client_id','transaction_id'])[last_cols].last()\n",
    "    last_month = df[df['transaction_datetime'] > '2019-02-18'].groupby(['client_id','transaction_id'])[last_cols].last()\n",
    "    \n",
    "    df['total_purchase_sum'] = all_hist.groupby('client_id')['purchase_sum'].sum()\n",
    "    df['last_30_purchase_sum'] = last_month.groupby('client_id')['purchase_sum'].sum()\n",
    "    df['total_product_quantity'] = all_hist.groupby('client_id')['product_quantity'].sum()\n",
    "    df['last_30_product_quantity_sum'] = last_month.groupby('client_id')['product_quantity'].sum()\n",
    "    df['total_regular_points_received'] = all_hist.groupby('client_id')['regular_points_received'].sum()\n",
    "    df['last_30_regular_points_received'] = last_month.groupby('client_id')['regular_points_received'].sum()\n",
    "    df['total_express_points_received'] = all_hist.groupby('client_id')['express_points_received'].sum()\n",
    "    df['last_30_express_points_received'] = last_month.groupby('client_id')['express_points_received'].sum()\n",
    "    df['total_regular_points_spent'] = all_hist.groupby('client_id')['regular_points_spent'].sum()\n",
    "    df['last_30_regular_points_spent'] = last_month.groupby('client_id')['regular_points_spent'].sum()\n",
    "    df['total_express_points_spent'] = all_hist.groupby('client_id')['express_points_spent'].sum()\n",
    "    df['last_30_express_points_spent'] = last_month.groupby('client_id')['express_points_spent'].sum()\n",
    "    df['total_regular_points_balance'] = df['total_regular_points_received'] - df['total_regular_points_spent']\n",
    "    df['total_express_points_balance'] = df['total_express_points_received'] - df['total_express_points_spent']\n",
    "    df['last_30_regular_points_balance'] = df['last_30_regular_points_received'] - df['last_30_regular_points_spent']\n",
    "    df['last_30_express_points_balance'] = df['last_30_express_points_received'] - df['total_express_points_spent']\n",
    "    df['unique_stores'] = all_hist.groupby('client_id')[['store_id']].nunique()\n",
    "    df['last_30_unique_stores'] = last_month.groupby('client_id')[['store_id']].nunique()\n",
    "    df['days_delay'] = (all_hist.groupby('client_id')['transaction_datetime'].iloc[0] - \n",
    "                        all_hist.groupby('client_id')['transaction_datetime'].iloc[-1]).dt.days\n",
    "    df['last_days_delay'] = (last_month.groupby('client_id')['transaction_datetime'].iloc[0] - \n",
    "                        last_month.groupby('client_id')['transaction_datetime'].iloc[-1]).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для mean target кодирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train_df, y_train, valid_df, skf):    \n",
    "    glob_mean = y_train.mean()\n",
    "    train_df = pd.concat([train_df, pd.Series(y_train, name='y')], axis=1)\n",
    "    new_train_df = train_df.copy()\n",
    "    \n",
    "    cat_features = train_df.columns[train_df.dtypes == 'object'].tolist()\n",
    "    \n",
    "    for col in cat_features:\n",
    "        new_train_df[col + '_mean_target'] = [glob_mean for _ in range(new_train_df.shape[0])]\n",
    "        \n",
    "    for train_idx, valid_idx in skf.split(train_df, y_train):\n",
    "        train_df_cv, valid_df_cv = train_df.iloc[train_idx, :], train_df.iloc[valid_idx, :]\n",
    "        \n",
    "        for col in cat_features:\n",
    "            \n",
    "            means = valid_df_cv[col].map(train_df_cv.groupby(col)['y'].means())\n",
    "            valid_df_cv[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "            \n",
    "        new_train_df.iloc[valid_idx] = valid_df_cv\n",
    "        \n",
    "    new_train_df.drop(cat_features + ['y'], axis=1, inplace=True)\n",
    "    \n",
    "    for col in cat_features:\n",
    "        means = valid_df[col].map(train_df.groupby(col)['y'].mean())\n",
    "        valid_df[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "        \n",
    "    valid_df.drop(train_df.columns[train_df.dtypes == 'object'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_train_df, valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для визуализации ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_plot(y_test, preds):\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_color_codes(\"muted\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    fpr, tpr, thresholds_ = roc_curve(y_test, preds, pos_label=1)\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
